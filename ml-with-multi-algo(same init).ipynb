{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26fd8d7b-b779-4be6-baf2-29ed21caa526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('breast_cancer_wisconsin.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e02bccb5-07f4-4ec4-aeb0-b9f040a9c044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my worked link\n",
    "# https://colab.research.google.com/drive/1LytPVmU9fHyijW6FxdGq46WrYsrBo1AI#scrollTo=yoP_gTIrHwF4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec665ec1-1248-4d9a-841c-d1fd74cda610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "0    842302         M        17.99         10.38          122.80     1001.0   \n",
      "1    842517         M        20.57         17.77          132.90     1326.0   \n",
      "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
      "3  84348301         M        11.42         20.38           77.58      386.1   \n",
      "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
      "\n",
      "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
      "0          0.11840           0.27760          0.3001              0.14710   \n",
      "1          0.08474           0.07864          0.0869              0.07017   \n",
      "2          0.10960           0.15990          0.1974              0.12790   \n",
      "3          0.14250           0.28390          0.2414              0.10520   \n",
      "4          0.10030           0.13280          0.1980              0.10430   \n",
      "\n",
      "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
      "0  ...          17.33           184.60      2019.0            0.1622   \n",
      "1  ...          23.41           158.80      1956.0            0.1238   \n",
      "2  ...          25.53           152.50      1709.0            0.1444   \n",
      "3  ...          26.50            98.87       567.7            0.2098   \n",
      "4  ...          16.67           152.20      1575.0            0.1374   \n",
      "\n",
      "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
      "0             0.6656           0.7119                0.2654          0.4601   \n",
      "1             0.1866           0.2416                0.1860          0.2750   \n",
      "2             0.4245           0.4504                0.2430          0.3613   \n",
      "3             0.8663           0.6869                0.2575          0.6638   \n",
      "4             0.2050           0.4000                0.1625          0.2364   \n",
      "\n",
      "   fractal_dimension_worst  Unnamed: 32  \n",
      "0                  0.11890          NaN  \n",
      "1                  0.08902          NaN  \n",
      "2                  0.08758          NaN  \n",
      "3                  0.17300          NaN  \n",
      "4                  0.07678          NaN  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "# print(df.info())\n",
    "# print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8d74c66-f802-4938-9595-06c202a2d5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping columns that are not needed\n",
    "df = df.drop(columns=['id', 'Unnamed: 32'])\n",
    "\n",
    "#Map the target to binary values: 'M' to 1 (malignant), 'B' to 0 (benign)\n",
    "df['diagnosis'] = df['diagnosis'].map({'M': 1, 'B': 0})\n",
    "\n",
    "# Separate features and target datasets\n",
    "X = df.drop(columns=['diagnosis'])\n",
    "y = df['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91686b9c-c524-4534-959b-4fb5a9b0ec56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4355057e-ad50-4f7c-8a34-6e45038c322c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "075e6a9a-5f02-4540-925a-d7d2bd20fb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier()\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "820fc49c-eac4-459e-b36b-271b41eee7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Accuracy  Precision    Recall  F1 Score\n",
      "Random Forest        0.973684   0.973684  0.948718  0.961039\n",
      "SVM                  0.964912   0.948718  0.948718  0.948718\n",
      "KNN                  0.982456   1.000000  0.948718  0.973684\n",
      "Logistic Regression  0.973684   0.973684  0.948718  0.961039\n",
      "Decision Tree        0.956140   0.925000  0.948718  0.936709\n"
     ]
    }
   ],
   "source": [
    "# Function to evaluate the model\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Train, evaluate, and compare the models\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracy, precision, recall, f1 = evaluate_model(model, X_test, y_test)\n",
    "    results[name] = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1\n",
    "    }\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88e36e5-c1a6-44c0-8c50-d98aaf8aa0ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
